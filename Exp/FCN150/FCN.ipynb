{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd0d983b114054c7636e165f112b80209d041dfe9658d5ea22e40b43a2135c1c719",
   "display_name": "Python 3.8.10 64-bit ('tfenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/gdrive/MyDrive/ISBI_Dataset\")\n",
    "X_ids = next(os.walk('train'))[2]\n",
    "Y_ids = next(os.walk('label'))[2]\n",
    "print(len(X_ids),len(Y_ids))\n",
    "X_ids.sort()\n",
    "Y_ids.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_CHANNELS, IMG_WIDTH, IMG_HEIGHT = 3, 512, 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertical_symmetry(img_input):\n",
    "    return np.array(img_input)[::-1,:,:]\n",
    "    \n",
    "def horizental_symmetry(img_input):\n",
    "    return np.array(img_input)[:,::-1,:]\n",
    "\n",
    "def vertical_symmetry_2D(img_input):\n",
    "    return np.array(img_input)[::-1,:]\n",
    "    \n",
    "def horizental_symmetry_2D(img_input):\n",
    "    return np.array(img_input)[:,::-1]\n",
    "\n",
    "def cropping(img_input):\n",
    "    return img_input.crop((0,0,img_input.width/2,img_input.height/2)),img_input.crop((0,img_input.height/2-1,img_input.width/2,img_input.height-1)),img_input.crop((img_input.width/2-1,0,img_input.width-1,img_input.height/2-1)),img_input.crop((img_input.width/2-1,img_input.height/2-1,img_input.width-1,img_input.height-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((len(X_ids)*7, 256, 256, 3), dtype=np.float32)\n",
    "Y_train = np.zeros((len(Y_ids)*7, 256, 256, 1), dtype=np.bool)\n",
    "X_original=np.zeros((len(X_ids),512,512,3),dtype=np.float32)\n",
    "Y_original=np.zeros((len(Y_ids),512,512,1),dtype=np.float32)\n",
    "\n",
    "n=0\n",
    "m=0\n",
    "for id_ in (X_ids):\n",
    "    image = tf.keras.preprocessing.image.load_img(f'/gdrive/MyDrive/ISBI_Dataset/train/{id_}', target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "    # print(n,id_)\n",
    "    input_arr = tf.keras.preprocessing.image.img_to_array(image)[90:450,150:406]\n",
    "    image = tf.keras.preprocessing.image.array_to_img(input_arr, ).resize((256, 256))\n",
    "    original_image=tf.keras.preprocessing.image.array_to_img(input_arr, ).resize((512, 512))\n",
    "    X_train[n] = np.array(image)\n",
    "    X_original[m]=np.array(original_image)\n",
    "    img1,img2,img3,img4=cropping(tf.keras.preprocessing.image.array_to_img(X_original[m]))\n",
    "    n+=1\n",
    "    X_train[n]=np.array(img1.resize((256, 256)))\n",
    "    n+=1\n",
    "    X_train[n]=np.array(img2.resize((256, 256)))\n",
    "    n+=1\n",
    "    X_train[n]=np.array(img3.resize((256, 256)))\n",
    "    n+=1\n",
    "    X_train[n]=np.array(img4.resize((256, 256)))\n",
    "    n+=1\n",
    "    X_train[n]=np.array(tf.keras.preprocessing.image.array_to_img(vertical_symmetry(tf.keras.preprocessing.image.array_to_img(X_train[temp])),).resize((256, 256)))\n",
    "    n+=1\n",
    "    X_train[n]=np.array(tf.keras.preprocessing.image.array_to_img(horizental_symmetry(tf.keras.preprocessing.image.array_to_img(X_train[temp])),).resize((256, 256)))\n",
    "    n+=1\n",
    "    m+=1\n",
    "\n",
    "n=0\n",
    "m=0\n",
    "for  id_ in (Y_ids):\n",
    "    image = tf.keras.preprocessing.image.load_img(f'/gdrive/MyDrive/ISBI_Dataset/label/{id_}', \n",
    "                                                  target_size=(IMG_HEIGHT, IMG_WIDTH), color_mode=\"grayscale\")\n",
    "\n",
    "    print(n,id_)\n",
    "    input_arr = tf.keras.preprocessing.image.img_to_array(image)[90:450,150:406]\n",
    "    image = tf.keras.preprocessing.image.array_to_img(input_arr, ).resize((256, 256))\n",
    "    image = tf.keras.preprocessing.image.array_to_img(input_arr, ).resize((256, 256))\n",
    "    original_image=tf.keras.preprocessing.image.array_to_img(input_arr, ).resize((512, 512))\n",
    "    Y_train[n] = np.array(image)[:, :, np.newaxis]\n",
    "    Y_original[m]=np.array(original_image)[:, :, np.newaxis]\n",
    "    \n",
    "    img1,img2,img3,img4=cropping(tf.keras.preprocessing.image.array_to_img(Y_original[m]))\n",
    "    n+=1\n",
    "    Y_train[n]=np.array(img1.resize((256, 256)))[:, :, np.newaxis]\n",
    "    n+=1\n",
    "    Y_train[n]=np.array(img2.resize((256, 256)))[:, :, np.newaxis]\n",
    "    n+=1\n",
    "    Y_train[n]=np.array(img3.resize((256, 256)))[:, :, np.newaxis]\n",
    "    n+=1\n",
    "    Y_train[n]=np.array(img4.resize((256, 256)))[:, :, np.newaxis]\n",
    "    n+=1\n",
    "    Y_train[n]=np.array(vertical_symmetry_2D(tf.keras.preprocessing.image.array_to_img(Y_train[temp])),)[:, :, np.newaxis]\n",
    "    n+=1\n",
    "    Y_train[n]=np.array(horizental_symmetry_2D(tf.keras.preprocessing.image.array_to_img(Y_train[temp])),)[:, :, np.newaxis]\n",
    "    n+=1\n",
    "    m+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = plt.subplot(121)\n",
    "ax1.imshow(tf.keras.preprocessing.image.array_to_img(X_train[29]))\n",
    "ax2=plt.subplot(122)\n",
    "ax2.imshow(tf.keras.preprocessing.image.array_to_img(Y_train[29]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=tf.keras.layers.Input((256,256,3),name=\"Inputs\")\n",
    "s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
    "\n",
    "\n",
    "conv1=tf.keras.layers.ZeroPadding2D((1,1),input_shape=(3,256,256))(s)\n",
    "conv1=tf.keras.layers.Convolution2D(64,3,3,activation='relu')(conv1)\n",
    "conv1=tf.keras.layers.ZeroPadding3D((1,1))(conv1)\n",
    "conv1=tf.keras.layers.Convolution2D(64,3,3,activation='relu')(conv1)\n",
    "conv1=tf.keras.layers.MaxPooling2D((2,2),strides=(2,2))(conv1)\n",
    "\n",
    "conv2=tf.keras.layers.ZeroPadding2D((1,1))(conv1)\n",
    "conv2=tf.keras.layers.Convolution2D(128,3,3,activation='relu')(conv2)\n",
    "conv2=tf.keras.layers.ZeroPadding2D((1,1))(conv2)\n",
    "conv2=tf.keras.layers.Convolution2D(128,3,3,activation='relu')(conv2)\n",
    "conv2=tf.keras.layers.MaxPooling2D((2,2),strides=(2,2))(conv2)\n",
    "\n",
    "conv3=tf.keras.layers.ZeroPadding2D((1,1))(conv2)\n",
    "conv3=tf.keras.layers.Convolution2D(256,3,3,activation='relu')(conv3)\n",
    "conv3=tf.keras.layers.ZeroPadding2D((1,1))(conv3)\n",
    "conv3=tf.keras.layers.Convolution2D(256,3,3,activation='relu')(conv3)\n",
    "conv3=tf.keras.layers.ZeroPadding2D((1,1))(conv3)\n",
    "conv3=tf.keras.layers.Convolution2D(256,3,3,activation='relu')(conv3)\n",
    "conv3=tf.keras.layers.MaxPooling2D((2,2),strides=(2,2))(conv3)\n",
    "\n",
    "conv4=tf.keras.layers.ZeroPadding2D((1,1))(conv2)\n",
    "conv4=tf.keras.layers.Convolution2D(512,3,3,activation='relu')(conv4)\n",
    "conv4=tf.keras.layers.ZeroPadding2D((1,1))(conv4)\n",
    "conv4=tf.keras.layers.Convolution2D(512,3,3,activation='relu')(conv4)\n",
    "conv4=tf.keras.layers.ZeroPadding2D((1,1))(conv4)\n",
    "conv4=tf.keras.layers.Convolution2D(512,3,3,activation='relu')(conv4)\n",
    "conv4=tf.keras.layers.MaxPooling2D((2,2),strides=(2,2))(conv4)\n",
    "\n",
    "conv5=tf.keras.layers.ZeroPadding2D((1,1))(conv4)\n",
    "conv5=tf.keras.layers.Convolution2D(512,3,3,activation='relu')(conv5)\n",
    "conv5=tf.keras.layers.ZeroPadding2D((1,1))(conv5)\n",
    "conv5=tf.keras.layers.Convolution2D(512,3,3,activation='relu')(conv5)\n",
    "conv5=tf.keras.layers.ZeroPadding2D((1,1))(conv5)\n",
    "conv5=tf.keras.layers.Convolution2D(512,3,3,activation='relu')(conv5)\n",
    "conv5=tf.keras.layers.MaxPooling2D((2,2),strides=(2,2))(conv5)\n",
    "\n",
    "conv6=tf.keras.layers.Flatten()(conv5)\n",
    "conv6=tf.keras.layers.Dense(4096,activation='relu')(conv6)\n",
    "conv6=tf.keras.layers.Dropout(0.5)(conv6)\n",
    "conv6=tf.keras.layers.Dense(4096,activation='relu')(conv6)\n",
    "conv6=tf.keras.layers.Dropout(0.5)(conv6)\n",
    "outputs=tf.keras.layers.Dense(1000,activation='softmax')(conv6)\n",
    "\n",
    "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=8, epochs=1000)\n",
    "model.save(\"FCNModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results.history['accuracy'])\n",
    "plt.plot(results.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(results.history['loss'])\n",
    "plt.plot(results.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "test_id = random.choice(X_ids)\n",
    "print(test_id)\n",
    "img = tf.keras.preprocessing.image.load_img(f\"/gdrive/MyDrive/ISBI_Dataset/train/{test_id}\", target_size=(256, 256))\n",
    "input_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "input_array_model = np.array([input_array])\n",
    "predictions = model.predict(input_array_model)\n",
    "ax10=plt.subplot(121)\n",
    "ax10.imshow(np.asarray(Image.open(f\"/gdrive/MyDrive/ISBI_Dataset/train/{test_id}\")))\n",
    "ax11=plt.subplot(122)\n",
    "ax11.imshow(tf.keras.preprocessing.image.array_to_img(np.squeeze(predictions)[:, :, np.newaxis]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax12=plt.subplot(121)\n",
    "ax12.imshow(np.asarray(tf.keras.preprocessing.image.array_to_img(np.squeeze(predictions)[:, :, np.newaxis])))\n",
    "ax13=plt.subplot(122)\n",
    "train_id=test_id.replace('volume','labels')\n",
    "ax13.imshow(np.asarray(Image.open(f\"/gdrive/MyDrive/ISBI_Dataset/label/{train_id}\")))\n",
    "plt.show()"
   ]
  }
 ]
}